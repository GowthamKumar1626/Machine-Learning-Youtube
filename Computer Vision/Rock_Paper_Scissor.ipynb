{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rock Paper Scissor.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNlEdIJtGtni5mgrRgDjnJO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GowthamKumar1626/Machine-Learning-Youtube/blob/master/Computer%20Vision/Rock_Paper_Scissor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x56xnjj3PaNB",
        "colab_type": "text"
      },
      "source": [
        "**Hello Guys Welcome to the new session**<br>\n",
        "Today we will deal with rock paper scissor dataset.<br>\n",
        "Have you ever faced any problem with <b>Overfitting</b>?<br>\n",
        "Do you know how to solve the problem of overfitting in Image Classification task?<br>\n",
        "Join with me I will show you how to deal with it..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2RvFS8tQoIi",
        "colab_type": "text"
      },
      "source": [
        "## **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlFKHsejiDkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x. #For colab users\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42) #To make this notebook's output stable across runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSi1oIzYRKV0",
        "colab_type": "text"
      },
      "source": [
        "## **Dataset Builder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjtm3AncRDYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "builder = tfds.builder(\"rock_paper_scissors\")\n",
        "info = builder.info\n",
        "print(info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jlp4r_eRXFV",
        "colab_type": "text"
      },
      "source": [
        "**About info**<br>\n",
        "Each image size (300, 300, 3)<br>\n",
        "No.of labels: 3<br>\n",
        "No.of splits: 2 (train, test)<br>\n",
        "Total no.of examples: 2892"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1da5IcBRnEg",
        "colab_type": "text"
      },
      "source": [
        "## **Download dataset using builder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si7tjUfuRVSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "builder.download_and_prepare()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLvH3kvDRsto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train, val, test) = tfds.load(\"rock_paper_scissors\", split=[\"train\", \"test[:90%]\", \"test[90%:]\"], shuffle_files=True, as_supervised=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnO_c71NR8lm",
        "colab_type": "text"
      },
      "source": [
        "Note: as_supervised=True will return Tuple with image and labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0FEpDUfSDaC",
        "colab_type": "text"
      },
      "source": [
        "## **Collect class names**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISqhQJpdR7KV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = []\n",
        "for i in range(info.features['label'].num_classes):\n",
        "  class_names.append(info.features['label'].int2str(i))\n",
        "\n",
        "class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_e3JHdMSS0l",
        "colab_type": "text"
      },
      "source": [
        "## **Plot one random image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nfeHcu6SQRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image, label = next(iter(train))\n",
        "_ = plt.imshow(image)\n",
        "_ = plt.title(class_names[label])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irOecWz0Sdsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let us define some variables\n",
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 1000\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "IMAGE_SIZE = 180\n",
        "NUM_CLASSES = len(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP0G8pW_St0o",
        "colab_type": "text"
      },
      "source": [
        "## **A sequential model for rescale and resize**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U3wD5cQSssX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWbYL2NMTFXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resize_image = resize_and_rescale(np.expand_dims(image, axis=0))\n",
        "_ = plt.imshow(resize_image[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t33ZocXPTWS_",
        "colab_type": "text"
      },
      "source": [
        "## **Prepare train and val sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOCK1McnUSXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def prepare(dataset, shuffle=False, training=False):\n",
        "  if training:\n",
        "    dataset = dataset.map(lambda x,y: (resize_and_rescale(x, training=True), y),\n",
        "                        num_parallel_calls=AUTOTUNE)\n",
        "  else:\n",
        "    dataset = dataset.map(lambda x,y: (resize_and_rescale(x, training=False), y),\n",
        "                        num_parallel_calls=AUTOTUNE)\n",
        "  if shuffle:\n",
        "    dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "  dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "  return dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHUk3TouV7Up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = prepare(train, shuffle=True, training=True)\n",
        "val_ds = prepare(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1OnnSoSWE-P",
        "colab_type": "text"
      },
      "source": [
        "## **Create our MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqYDwkLMWDa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        layers.MaxPool2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer = \"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs = NUM_EPOCHS,\n",
        "    validation_data = val_ds\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPvGwbi9XFzu",
        "colab_type": "text"
      },
      "source": [
        "**Overfit**<br>\n",
        "Our training set achieved 100% accuracy, but validation set 62%\n",
        "Our model is overfitted\n",
        "Let us see learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TA5tDYYW6xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(history.history).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmZCFnVEXcvv",
        "colab_type": "text"
      },
      "source": [
        "Learning curves are too bad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVqvWRq-XfQj",
        "colab_type": "text"
      },
      "source": [
        "## **Plot some predictions with overfitted model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gCV2b7WXaue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "for i, datapoint in enumerate(test.take(25)):\n",
        "  ax = plt.subplot(5, 5, i+1)\n",
        "  plt.imshow(datapoint[0])\n",
        "  image = resize_and_rescale(datapoint[0])\n",
        "  image = np.expand_dims(image, axis = 0)\n",
        "\n",
        "  if datapoint[1] == np.argmax(model.predict(image)):\n",
        "    plt.title(class_names[np.argmax(model.predict(image))], color=\"green\")\n",
        "  else:\n",
        "    plt.title(class_names[np.argmax(model.predict(image))], color=\"red\")\n",
        "\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT1Oph6wYSOM",
        "colab_type": "text"
      },
      "source": [
        "OMG! More than 10 images are wrong preditions out of 25 images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz9M-IFdYYwT",
        "colab_type": "text"
      },
      "source": [
        "We will solve this problem in my next session, please watch next video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unFfzWsH1BE3",
        "colab_type": "text"
      },
      "source": [
        "**Hello Guys**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz-rEmm91EFj",
        "colab_type": "text"
      },
      "source": [
        "Welocme back to session. Previously we created a model, that is `overfitted`<br>\n",
        "What we need to do now inorder to avoid `overfitting`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHmuX3EJ1Rkp",
        "colab_type": "text"
      },
      "source": [
        "## **Data Augmentation**\n",
        "It is a technique to increase the diversity or `randomness` of your training set by applying radom transformations. <br>\n",
        "This is the first step we need to do if our modelis overfitting (In case of Image classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMjdwuI61nIM",
        "colab_type": "text"
      },
      "source": [
        "Before that we will create a function for plotting our predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeVceT10fBFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def  plot_predictions(data, model, n_rows=5, n_cols=5):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  for i, datapoint in enumerate(data.take(n_rows * n_cols)):\n",
        "    ax = plt.subplot(n_rows, n_cols, i+1)\n",
        "    plt.imshow(datapoint[0])\n",
        "    image = resize_and_rescale(datapoint[0])\n",
        "    image = np.expand_dims(image, axis = 0)\n",
        "\n",
        "    if datapoint[1] == np.argmax(model.predict(image)):\n",
        "      plt.title(class_names[np.argmax(model.predict(image))], color=\"green\")\n",
        "    else:\n",
        "      plt.title(class_names[np.argmax(model.predict(image))], color=\"red\")\n",
        "\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Yi2mNO2Bkj",
        "colab_type": "text"
      },
      "source": [
        "Now lets write our augmentation code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XknLl2wG1_mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmentation = tf.keras.Sequential([\n",
        "      tf.keras.layers.experimental.preprocessing.RandomZoom(0.3),\n",
        "      tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal_and_vertical'),\n",
        "      tf.keras.layers.experimental.preprocessing.RandomRotation(0.3)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TomeHwN2clu",
        "colab_type": "text"
      },
      "source": [
        "## **Plot some augmented images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9dKeEGE2bmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image, lable = next(iter(train))\n",
        "\n",
        "augmented_images = augmentation(np.expand_dims(image, axis=0))\n",
        "_ = plt.imshow(augmented_images[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6nAIH2U2ua7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  augmented_images = augmentation(np.expand_dims(image, axis=0))\n",
        "  ax = plt.subplot(3, 3, i+1)\n",
        "  plt.imshow(augmented_images[0])\n",
        "  plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otv6EtLX3FI-",
        "colab_type": "text"
      },
      "source": [
        "Yeah it's cool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpfEg1cw3Hbj",
        "colab_type": "text"
      },
      "source": [
        "Now let make some changes in prepare function (which we defined in last session) <br>\n",
        "Now we will add `augmentation` part in prepare function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p4pjHeS3C0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def prepare(dataset, shuffle=False, augment=False):\n",
        "  dataset = dataset.map(lambda x,y: (resize_and_rescale(x), y),\n",
        "                        num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  if shuffle:\n",
        "    dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "  dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "  if augment:\n",
        "    dataset = dataset.map(lambda x,y: (augmentation(x, training=True), y),\n",
        "                          num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  return dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbDphogA349-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = prepare(train, shuffle=True, augment=True)\n",
        "val_ds = prepare(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlMG17Q-4BPN",
        "colab_type": "text"
      },
      "source": [
        "Ok now we will grab our previus defined model.<br>\n",
        "* With out augmentation it is overfitted.<br>\n",
        "* Now let us check Whether the same situation will repeat or not?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFrk2rvQ4AHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        layers.MaxPool2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer = \"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs = NUM_EPOCHS,\n",
        "    validation_data = val_ds\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQVrP5ZE4unV",
        "colab_type": "text"
      },
      "source": [
        "Ok it seems our model is not ovefitted now. Great! But accuracy is too low."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI6jENsH43B5",
        "colab_type": "text"
      },
      "source": [
        "Let me first plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVaNYzyJ4VF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(history.history).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cszEMniX4_45",
        "colab_type": "text"
      },
      "source": [
        "Yeah everything is fine. But low accuracy.<br>\n",
        "* Before we run our model on 5 epochs.Now we will run our model on more epochs let num_epochs=30 and i will use `EarlyStopping`callback to stop when our model is overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfTL_1fy4-Gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        layers.MaxPool2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer = \"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs = 30,\n",
        "    validation_data = val_ds,\n",
        "    callbacks = [tf.keras.callbacks.EarlyStopping(patience=2)]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOB9DL1x6FTm",
        "colab_type": "text"
      },
      "source": [
        "It seems we didn't achieve much. Let us plot learning curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waz6UBT45cgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(history.history).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvhXqppl6O-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_ds = prepare(test)\n",
        "model.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTeZ6pfD6Wi_",
        "colab_type": "text"
      },
      "source": [
        "`62.16%` accuracy on test set. Can we increase more? Yes we can..<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYYl7y5c6fdt",
        "colab_type": "text"
      },
      "source": [
        "Let me create a new model with new architecture. Previous model is not giving good accuracy. Let us make some changes in model. <br> In this new model I am going to change `Optimizer` to `RMSProp` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8Ajr8A260OZ",
        "colab_type": "text"
      },
      "source": [
        "## **New model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pH-VoXq6UqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(3, activation='softmax')\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=15,\n",
        "    validation_data = val_ds\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN99_PGK9Gbx",
        "colab_type": "text"
      },
      "source": [
        "I think it is good. Plot learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrdIeQdN77kU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(history.history).plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIDlAK8h9P8z",
        "colab_type": "text"
      },
      "source": [
        "It is pretty Good. Let us plot some predicitons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsHxqUsr9OuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_predictions(test, model, n_rows=6, n_cols=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhGmgoWP9dtw",
        "colab_type": "text"
      },
      "source": [
        "Out ot `36` images only one image is wrong ðŸ˜ƒ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG6D_bTl9Zoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_ds = prepare(test)\n",
        "model.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFLHUKRf9orx",
        "colab_type": "text"
      },
      "source": [
        "`94.59` Awsome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8sFtbzs9tTN",
        "colab_type": "text"
      },
      "source": [
        "Thank you guys. We can do more. Try to achive greater than this <br>\n",
        "Follow my channel Thank You Guys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqWodB2x9nWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}