{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification using TFDS(EuroSAT Dataset) ",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPHl66WE84CYnEmf4dlQwHX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GowthamKumar1626/Machine-Learning-Youtube/blob/master/Computer%20Vision/Image_Classification_using_TFDS(EuroSAT_Dataset).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFFsizClPbTz",
        "colab_type": "text"
      },
      "source": [
        "## **Hello Guys! Welcome to the new Session**\n",
        "Todays we will learn about how to use tensorflow datasets.<br>\n",
        "Note: Use <b>GPU</b> as runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idP5nq5cEVba",
        "colab_type": "text"
      },
      "source": [
        "## Prerequisite\n",
        "<ul>\n",
        "  <li>Install tensorflow-datasets:</li> \n",
        "      <strong>pip install tensorflow-datasets</strong> (Please avoid this step is you are using colab)\n",
        "  <li>Search for datasets:</li>\n",
        "      https://www.tensorflow.org/datasets/catalog/overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfCNwOwjRe4S",
        "colab_type": "text"
      },
      "source": [
        "## **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrsMeVD-Vb0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqtoVh52XaMB",
        "colab_type": "text"
      },
      "source": [
        "**Get info of dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLaqHdvQXWAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tfds.builder('eurosat')\n",
        "info = dataset.info\n",
        "print(info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXT9xX__XqEf",
        "colab_type": "text"
      },
      "source": [
        "Eurosat contains 2 datasets. We are using rgb datset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dUWqD_cXkEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "info.features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-ZdD6skXxjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = []\n",
        "for i in range(info.features[\"label\"].num_classes):\n",
        "  class_names.append(info.features[\"label\"].int2str(i))\n",
        "\n",
        "class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgCN3je0X_eZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(info.splits.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwsefp81YDvQ",
        "colab_type": "text"
      },
      "source": [
        "This datset contains only one split train with 27000 images with 10 classes, You can get all these information in info which is mentioned above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC8EqdFhYODy",
        "colab_type": "text"
      },
      "source": [
        "## **Get Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTE8xpJkYCxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train, val, test) = tfds.load(\"eurosat/rgb\", split=[\"train[:80%]\", \"train[80%:90%]\", \"train[90%:]\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8aNnmkcYbF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl1KafT7Yj8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datapoint = next(iter(train))\n",
        "datapoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPeiCc8hYsgB",
        "colab_type": "text"
      },
      "source": [
        "This is a dictionary with 3 keys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RggHc0HYvod",
        "colab_type": "text"
      },
      "source": [
        "## **Plot some images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KLQWIsXYp8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "for i, datapoint in enumerate(tfds.as_numpy(train.take(25))):\n",
        "  ax = plt.subplot(5, 5, i+1)\n",
        "  plt.imshow(datapoint[\"image\"])\n",
        "  plt.title(class_names[datapoint[\"label\"]])\n",
        "  plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jAMzcVGZHCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "IMAGE_SHAPE = [180, 180]\n",
        "NUM_CLASSES = info.features[\"label\"].num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQEc5TuVZXK_",
        "colab_type": "text"
      },
      "source": [
        "## **Data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dB_wo_MZVf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.uniform(())  # This will generate a radom floating number from 0-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dt95nokZjJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def prepare_training_data(datapoint):\n",
        "  input_image = tf.image.resize(datapoint[\"image\"], IMAGE_SHAPE)\n",
        "\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    input_image = tf.image.random_flip_left_right(input_image)\n",
        "    input_image = tf.image.random_flip_up_down(input_image)\n",
        "    input_image = tf.image.random_brightness(input_image, max_delta=0.3)\n",
        "    input_image = tf.image.random_saturation(input_image, lower=0.75, upper=1.5)\n",
        "    input_image = tf.image.random_contrast(input_image, lower=0.75, upper=1.5)\n",
        "\n",
        "  input_image = preprocess_input(input_image)\n",
        "\n",
        "  return input_image, datapoint[\"label\"]\n",
        "\n",
        "def prepare_validation_data(datapoint):\n",
        "  input_image = tf.image.resize(datapoint[\"image\"], IMAGE_SHAPE)\n",
        "  input_image = preprocess_input(input_image)\n",
        "\n",
        "  return input_image, datapoint[\"label\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UokMG89Rastv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.map(prepare_training_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "validation = val.map(prepare_validation_data)\n",
        "\n",
        "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "validation_dataset = validation.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_vTNSxbbQFK",
        "colab_type": "text"
      },
      "source": [
        "## **Visualization of image after preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daQVERBSbVzS",
        "colab_type": "text"
      },
      "source": [
        "Note: We will observe weird images, beacuse we used preprocess_input() function which is imported from resnet. This will scale the values in range [-1,1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aekaPBhYbOyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i+1)\n",
        "  for datapoint in tfds.as_numpy(train_dataset.take(1)):\n",
        "    plt.imshow(datapoint[0][0].astype('uint8'))\n",
        "    plt.title(class_names[datapoint[1][0]])\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMrS8huicNBX",
        "colab_type": "text"
      },
      "source": [
        "Without using uint8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_eqcu8ob_Kc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "for i in range(4):\n",
        "  ax = plt.subplot(2, 2, i+1)\n",
        "  for datapoint in tfds.as_numpy(train_dataset.take(1)):\n",
        "    plt.imshow(datapoint[0][0])\n",
        "    plt.title(class_names[datapoint[1][0]])\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJeU7sP_cfb8",
        "colab_type": "text"
      },
      "source": [
        "## **Building model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzIxAaWzcavR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resnet = ResNet50(input_shape=IMAGE_SHAPE+[3], weights='imagenet', include_top=False)\n",
        "\n",
        "for layer in resnet.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(resnet.output)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "predicition = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=resnet.input, outputs=predicition)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF_NvafedMea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fePHBDy9ddju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STEPS_PER_EPOCH = int(info.splits[\"train\"].num_examples * 0.8)//BATCH_SIZE\n",
        "VALIDATION_STEPS = int(info.splits[\"train\"].num_examples * 0.1)//BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJpXxnDgdtMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs = NUM_EPOCHS,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    validation_data=validation_dataset,\n",
        "    validation_steps=VALIDATION_STEPS\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MELiVZ7fd74K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(\n",
        "    history.history\n",
        ").plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-IQ0rzggIER",
        "colab_type": "text"
      },
      "source": [
        "## **Evaluating results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j805qpLh2A2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = test.map(prepare_validation_data)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTx490gNivPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKm6UgGpix0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "for i, datapoint in enumerate(tfds.as_numpy(test.take(25))):\n",
        "  ax = plt.subplot(5, 5, i+1)\n",
        "  plt.imshow(datapoint[\"image\"])\n",
        "  image = tf.image.resize(datapoint[\"image\"], IMAGE_SHAPE)\n",
        "  image = preprocess_input(image)\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "\n",
        "  if datapoint[\"label\"] == np.argmax(model.predict(image)):\n",
        "    plt.title(class_names[np.argmax(model.predict(image))], color=\"green\")\n",
        "  else:\n",
        "    plt.title(class_names[np.argmax(model.predict(image))], color=\"red\")\n",
        "\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unMgryTfj5lY",
        "colab_type": "text"
      },
      "source": [
        "Thank You GUys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLrSY7fIjn9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}